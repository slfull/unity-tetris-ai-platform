{
    "name": "root",
    "gauges": {
        "Board.Policy.Entropy.mean": {
            "value": 2.9674456119537354,
            "min": 2.954284429550171,
            "max": 3.013091564178467,
            "count": 24
        },
        "Board.Policy.Entropy.sum": {
            "value": 29674.45703125,
            "min": 4187.2421875,
            "max": 30112.8359375,
            "count": 24
        },
        "Board.Step.mean": {
            "value": 499988.0,
            "min": 269957.0,
            "max": 499988.0,
            "count": 24
        },
        "Board.Step.sum": {
            "value": 499988.0,
            "min": 269957.0,
            "max": 499988.0,
            "count": 24
        },
        "Board.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.13665196299552917,
            "min": -0.7153193950653076,
            "max": 0.017654361203312874,
            "count": 24
        },
        "Board.Policy.ExtrinsicValueEstimate.sum": {
            "value": -21.59101104736328,
            "min": -113.02046203613281,
            "max": 2.789389133453369,
            "count": 24
        },
        "Board.Policy.CuriosityValueEstimate.mean": {
            "value": 0.5458380579948425,
            "min": 0.5080496668815613,
            "max": 2.380476236343384,
            "count": 24
        },
        "Board.Policy.CuriosityValueEstimate.sum": {
            "value": 86.24241638183594,
            "min": 49.9900016784668,
            "max": 367.1726379394531,
            "count": 24
        },
        "Board.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 24
        },
        "Board.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 24
        },
        "Board.Environment.EpisodeLength.mean": {
            "value": 4999.0,
            "min": 3348.3333333333335,
            "max": 4999.0,
            "count": 23
        },
        "Board.Environment.EpisodeLength.sum": {
            "value": 9998.0,
            "min": 6766.0,
            "max": 12838.0,
            "count": 23
        },
        "Board.Environment.CumulativeReward.mean": {
            "value": -0.9999999747378752,
            "min": -5.991100158949848,
            "max": -0.9999999747378752,
            "count": 23
        },
        "Board.Environment.CumulativeReward.sum": {
            "value": -1.9999999494757503,
            "min": -12.567999778082594,
            "max": -1.9999999494757503,
            "count": 23
        },
        "Board.Policy.ExtrinsicReward.mean": {
            "value": -0.9999999747378752,
            "min": -5.991100158949848,
            "max": -0.9999999747378752,
            "count": 23
        },
        "Board.Policy.ExtrinsicReward.sum": {
            "value": -1.9999999494757503,
            "min": -12.567999778082594,
            "max": -1.9999999494757503,
            "count": 23
        },
        "Board.Policy.CuriosityReward.mean": {
            "value": 27.697464918717742,
            "min": 0.2365121195713679,
            "max": 32.542897310107946,
            "count": 23
        },
        "Board.Policy.CuriosityReward.sum": {
            "value": 55.394929837435484,
            "min": 0.7095363587141037,
            "max": 65.08579462021589,
            "count": 23
        },
        "Board.Losses.PolicyLoss.mean": {
            "value": 0.13235573427130778,
            "min": 0.04540705072383086,
            "max": 0.18231361297269663,
            "count": 22
        },
        "Board.Losses.PolicyLoss.sum": {
            "value": 0.13235573427130778,
            "min": 0.04540705072383086,
            "max": 0.18231361297269663,
            "count": 22
        },
        "Board.Losses.ValueLoss.mean": {
            "value": 0.0007260175450937822,
            "min": 0.00029251255521861217,
            "max": 0.07926636299428841,
            "count": 22
        },
        "Board.Losses.ValueLoss.sum": {
            "value": 0.0007260175450937822,
            "min": 0.00029251255521861217,
            "max": 0.07926636299428841,
            "count": 22
        },
        "Board.Policy.LearningRate.mean": {
            "value": 4.351298549599988e-06,
            "min": 4.351298549599988e-06,
            "max": 0.000132717055761,
            "count": 22
        },
        "Board.Policy.LearningRate.sum": {
            "value": 4.351298549599988e-06,
            "min": 4.351298549599988e-06,
            "max": 0.000132717055761,
            "count": 22
        },
        "Board.Policy.Epsilon.mean": {
            "value": 0.10145040000000001,
            "min": 0.10145040000000001,
            "max": 0.14423899999999995,
            "count": 22
        },
        "Board.Policy.Epsilon.sum": {
            "value": 0.10145040000000001,
            "min": 0.10145040000000001,
            "max": 0.14423899999999995,
            "count": 22
        },
        "Board.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 22
        },
        "Board.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 22
        },
        "Board.Losses.CuriosityForwardLoss.mean": {
            "value": 0.11919836873809496,
            "min": 0.025869762680182855,
            "max": 0.15158305938045183,
            "count": 22
        },
        "Board.Losses.CuriosityForwardLoss.sum": {
            "value": 0.11919836873809496,
            "min": 0.025869762680182855,
            "max": 0.15158305938045183,
            "count": 22
        },
        "Board.Losses.CuriosityInverseLoss.mean": {
            "value": 2.461798055966695,
            "min": 2.44077738126119,
            "max": 2.636721674601237,
            "count": 22
        },
        "Board.Losses.CuriosityInverseLoss.sum": {
            "value": 2.461798055966695,
            "min": 2.44077738126119,
            "max": 2.636721674601237,
            "count": 22
        },
        "Board.Self-play.ELO.mean": {
            "value": 719.5788321755022,
            "min": 719.5788321755022,
            "max": 732.3832746304519,
            "count": 14
        },
        "Board.Self-play.ELO.sum": {
            "value": 719.5788321755022,
            "min": 719.5788321755022,
            "max": 732.3832746304519,
            "count": 14
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1751530038",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "E:\\miniconda\\envs\\mlagents\\Scripts\\mlagents-learn ./config/trainer_config.yaml --run-id=SlfullTetris_run --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1751531796"
    },
    "total": 1757.8440594000276,
    "count": 1,
    "self": 0.5776580000529066,
    "children": {
        "run_training.setup": {
            "total": 0.3312999999616295,
            "count": 1,
            "self": 0.3312999999616295
        },
        "TrainerController.start_learning": {
            "total": 1756.935101400013,
            "count": 1,
            "self": 3.7222674135118723,
            "children": {
                "TrainerController._reset_env": {
                    "total": 30.964594300021417,
                    "count": 4,
                    "self": 30.964594300021417
                },
                "TrainerController.advance": {
                    "total": 1722.0588736864738,
                    "count": 231440,
                    "self": 3.347371339215897,
                    "children": {
                        "env_step": {
                            "total": 1621.2061926478054,
                            "count": 231440,
                            "self": 494.51788909581956,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1124.4670626863372,
                                    "count": 231440,
                                    "self": 9.962392378947698,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1114.5046703073895,
                                            "count": 231440,
                                            "self": 1114.5046703073895
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.221240865648724,
                                    "count": 231440,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1743.1961664033588,
                                            "count": 231440,
                                            "is_parallel": true,
                                            "self": 1414.0289559144294,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0761276000412181,
                                                    "count": 4,
                                                    "is_parallel": true,
                                                    "self": 0.0011928001185879111,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.07493479992263019,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.07493479992263019
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 329.0910828888882,
                                                    "count": 231440,
                                                    "is_parallel": true,
                                                    "self": 13.873114134650677,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 11.147873212117702,
                                                            "count": 231440,
                                                            "is_parallel": true,
                                                            "self": 11.147873212117702
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 260.6752351889154,
                                                            "count": 231440,
                                                            "is_parallel": true,
                                                            "self": 260.6752351889154
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 43.39486035320442,
                                                            "count": 231440,
                                                            "is_parallel": true,
                                                            "self": 27.2482111309655,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 16.14664922223892,
                                                                    "count": 462880,
                                                                    "is_parallel": true,
                                                                    "self": 16.14664922223892
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 97.50530969945248,
                            "count": 231440,
                            "self": 7.574854549369775,
                            "children": {
                                "process_trajectory": {
                                    "total": 55.39290034992155,
                                    "count": 231440,
                                    "self": 52.34373234992381,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 3.049167999997735,
                                            "count": 5,
                                            "self": 3.049167999997735
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 34.53755480016116,
                                    "count": 22,
                                    "self": 16.74663860083092,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 17.79091619933024,
                                            "count": 660,
                                            "self": 17.79091619933024
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.00006091594696e-07,
                    "count": 1,
                    "self": 8.00006091594696e-07
                },
                "TrainerController._save_models": {
                    "total": 0.18936519999988377,
                    "count": 1,
                    "self": 0.02791199996136129,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.16145320003852248,
                            "count": 1,
                            "self": 0.16145320003852248
                        }
                    }
                }
            }
        }
    }
}